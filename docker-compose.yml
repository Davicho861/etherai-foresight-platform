version: '3.8'

services:
  db:
    image: postgres:15-alpine
    container_name: praevisio_db
    environment:
      POSTGRES_USER: praevisio
      POSTGRES_PASSWORD: praevisio
      POSTGRES_DB: praevisio
    volumes:
      - praevisio_db_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U praevisio -d praevisio"]
      interval: 5s
      timeout: 5s
      retries: 12

  backend:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: praevisio_backend
    ports:
      - '4000:4000'
    environment:
      PRAEVISIO_BEARER_TOKEN: ${PRAEVISIO_BEARER_TOKEN:-demo-token}
      DATABASE_URL: ${DATABASE_URL:-postgresql://praevisio:praevisio@db:5432/praevisio?schema=public}
      PORT: '4000'
      # Point to the mock Ollama service in the Docker network
      OLLAMA_URL: 'http://ollama-mock:11434/api/generate'
    depends_on:
      db:
        condition: service_healthy
      prisma-seed:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:4000/api/platform-status -H \"Authorization: Bearer ${PRAEVISIO_BEARER_TOKEN:-demo-token}\" || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 12
    volumes:
      - backend_node_modules:/app/server/node_modules

  prisma-seed:
    build:
      context: .
      dockerfile: Dockerfile.backend
    container_name: praevisio_prisma_seed
    # Do not mount the host workspace to avoid node_modules conflicts during npm install
    environment:
      DATABASE_URL: ${DATABASE_URL:-postgresql://praevisio:praevisio@db:5432/praevisio?schema=public}
    depends_on:
      db:
        condition: service_healthy
    # Run migrations and seed using the built backend image as a one-shot job.
    # Important: do NOT keep the container sleeping; let it exit with 0 on success
    # so other services can depend on its successful completion.
    command: sh -c "npx prisma migrate deploy --schema=./prisma/schema.prisma && npx prisma db seed --schema=./prisma/schema.prisma"
    restart: 'no'

  frontend:
    build:
      context: .
      dockerfile: Dockerfile.frontend
    container_name: praevisio_frontend
    working_dir: /app
    ports:
      - '3002:3002'
    depends_on:
      backend:
        condition: service_healthy
    environment:
      VITE_API_BASE_URL: 'http://backend:4000'
      NODE_ENV: development
    volumes:
      # Mount only the source files needed for hot-reload to avoid overwriting
      # the rest of the image filesystem (including node_modules).
      - ./src:/app/src:cached
      - ./public:/app/public:cached
      - ./index.html:/app/index.html:cached
      - ./package.json:/app/package.json:cached
      - ./package-lock.json:/app/package-lock.json:cached
      - ./vite.config.ts:/app/vite.config.ts:cached
      - ./tsconfig.json:/app/tsconfig.json:cached
      # Keep node_modules isolated in a named volume populated from the image
      - praevisio_frontend_node_modules:/app/node_modules
    # On first start, if the named volume is empty, install dependencies into it.
    # This guarantees /app/node_modules contains the project deps (including vite)
    # while keeping dependencies isolated in a Docker volume thereafter.
    command: ["sh", "-c", "if [ ! -d /app/node_modules/vite ]; then echo 'vite missing in volume — installing frontend deps...' && npm ci --no-audit --no-fund --prefer-offline && npm install --no-audit --no-fund vite@7.1.7 @vitejs/plugin-react-swc --no-save; fi && NODE_ENV=development vite --host 0.0.0.0 --port 3002"]
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:3002 || exit 1"]
      interval: 10s
      timeout: 10s
      retries: 12
      start_period: 10s
    restart: 'no'

  # NOTE: The e2e-tester service was removed from the primary docker-compose
  # stack. Playwright E2E tests are executed by the `npm run validate` flow
  # (scripts/validate_local.sh) which runs them from the host or an
  # ephemeral container. Keeping the e2e-tester as a long-running service
  # caused healthcheck complexity and prevented the compose stack from
  # stabilizing as a "live" ecosystem. If you need a containerized runner,
  # consider adding a separate compose file (e.g. docker-compose.test.yml)
  # used only by CI or validation flows.

  ollama-mock:
    image: node:20-bullseye-slim
    container_name: praevisio_ollama_mock
    working_dir: /app
    volumes:
      - ./:/app:cached
    command: sh -c "node ./scripts/mock_ollama.js"
    ports:
      - '11434:11434'
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:11434/ || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 12
      start_period: 5s
    restart: 'no'

  # ChromaDB for Conciencia Colectiva 3.0 (Vector Database)
  chromadb:
    image: chromadb/chroma:latest
    container_name: praevisio_chromadb
    ports:
      - '8000:8000'
    volumes:
      - chromadb_data:/chroma/chroma
    environment:
      - CHROMA_SERVER_HOST=0.0.0.0
      - CHROMA_SERVER_HTTP_PORT=8000
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/api/v1/heartbeat || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 12
    restart: 'no'

  # Neo4j for Archivo Akáshico and Lóbulo Causal (Graph Database)
  neo4j:
    image: neo4j:5.20
    container_name: praevisio_neo4j
    ports:
      - '7474:7474'
      - '7687:7687'
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    environment:
      - NEO4J_AUTH=neo4j/praevisio
      - NEO4J_PLUGINS=["graph-data-science"]
    healthcheck:
      test: ["CMD-SHELL", "cypher-shell -u neo4j -p praevisio 'MATCH () RETURN count(*) limit 1;' || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 12
    restart: 'no'

volumes:
  praevisio_db_data:
  backend_node_modules:
  e2e_tester_node_modules:
  praevisio_frontend_node_modules:
  chromadb_data:
  neo4j_data:
  neo4j_logs:

networks:
  default:
    name: praevisio_network
